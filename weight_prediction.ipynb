{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19536234-2ee5-4396-9eb9-4d6e8bdb5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import platform\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pytesseract import Output\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2dfa6abc-77c0-4476-95c7-31e030fe83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pytesseract setup\n",
    "\n",
    "def init():\n",
    "    if (platform.system()==\"Darwin\"):\n",
    "        pytesseract.pytesseract.tesseract_cmd = r\"/opt/homebrew/bin/tesseract\"\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a32049d-38d3-4251-9f32-aac14a06ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_from_link(image_link):   \n",
    "    image_name = \"image.jpg\"\n",
    "\n",
    "    try:\n",
    "        # Download the image\n",
    "        response = requests.get(image_link, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            # Save the image locally\n",
    "            with open(image_name, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            return image_name\n",
    "        else:\n",
    "            print(f\"Failed to download image. Status code: {response.status_code}\")\n",
    "            return -1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0900c2ac-3172-4b8d-a33a-bf00533d7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_image(filename):\n",
    "    image = cv2.imread(filename)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh_image = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # # Apply Adaptive Mean Thresholding\n",
    "    # mean_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "    #                                     cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # # Apply Adaptive Gaussian Thresholding\n",
    "    # gaussian_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    #                                         cv2.THRESH_BINARY, 11, 2)\n",
    "    return thresh_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68de15d7-3b4e-44cb-a8bc-726e0e096448",
   "metadata": {},
   "outputs": [],
   "source": [
    "## constants\n",
    "# Entity map for dimensional indicators\n",
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
    "}\n",
    "\n",
    "# Regex patterns for dimensions\n",
    "patterns = {\n",
    "    \"weight\": r'\\b(\\d+(\\.\\d+)?\\s?(g|grams|kg|kilograms|lb|lbs|pounds))\\b',\n",
    "    \"length\": r'\\b(\\d+(\\.\\d+)?\\s?(cm|centimeters|mm|meters|inches|feet|ft))\\b',\n",
    "    \"voltage\": r'\\b(\\d+(\\.\\d+)?\\s?(V|volts|kV|kilovolts))\\b',\n",
    "    \"wattage\": r'\\b(\\d+(\\.\\d+)?\\s?(W|watts|kW|kilowatts))\\b',\n",
    "    \"volume\": r'\\b(\\d+(\\.\\d+)?\\s?(L|litres|ml|millilitres|gallon|cup|pint|quart))\\b'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e7c7a50-6db0-42e7-9e01-388e6059bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, angle):\n",
    "    \n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "    return rotated\n",
    "\n",
    "def get_words_with_metadata(image, orientation):\n",
    "\n",
    "    data = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
    "    words = []\n",
    "    for i in range(len(data['text'])):\n",
    "        word = data['text'][i].strip()\n",
    "        if word:\n",
    "            x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "            confidence = data['conf'][i]\n",
    "            words.append({\n",
    "                'word': word,\n",
    "                'position': {'x': x, 'y': y, 'width': w, 'height': h},\n",
    "                'orientation': orientation,\n",
    "                'confidence': confidence\n",
    "            })\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1608020c-c3d1-4a19-b58e-602851fbdb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dimensional_words(word_list):\n",
    "\n",
    "    extracted_words = {key: [] for key in patterns.keys()}\n",
    "\n",
    "    for word_data in word_list:\n",
    "        word = word_data['word']\n",
    "        for key, pattern in patterns.items():\n",
    "            matches = re.findall(pattern, word, re.IGNORECASE)\n",
    "            if matches:\n",
    "                extracted_words[key].append({\n",
    "                    'word': matches[0][0],\n",
    "                    'metadata': word_data\n",
    "                })\n",
    "\n",
    "    return extracted_words\n",
    "\n",
    "def extract_and_classify(image):\n",
    "\n",
    "    # Get words from the original image (0 degrees orientation)\n",
    "    words_0_deg = get_words_with_metadata(image, orientation='0 degrees')\n",
    "\n",
    "    # Rotate image +90 degrees and extract words\n",
    "    image_90_deg = rotate_image(image, 90)\n",
    "    words_90_deg = get_words_with_metadata(image_90_deg, orientation='+90 degrees')\n",
    "\n",
    "    # Rotate image -90 degrees and extract words\n",
    "    image_neg_90_deg = rotate_image(image, -90)\n",
    "    words_neg_90_deg = get_words_with_metadata(image_neg_90_deg, orientation='-90 degrees')\n",
    "\n",
    "    # Combine all words from all orientations\n",
    "    all_words = words_0_deg + words_90_deg + words_neg_90_deg\n",
    "    \n",
    "    # Classify words into dimensional categories\n",
    "    classified_words = extract_dimensional_words(all_words)\n",
    "\n",
    "    return classified_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495f27d-83d5-4d88-9229-f5d9d73775ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2eb08e00-1412-415a-9548-0cf23ab783e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_data = {'weight': [], 'length': [], 'voltage': [], 'wattage': [], 'volume': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3416c97a-84cb-4dd7-a17f-71a9e15b2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "## return the possible output strings with probabilities\n",
    "\n",
    "def get_data_from_image(image_link):\n",
    "    image_metadata = []\n",
    "\n",
    "    #get the image from link:\n",
    "    file_name = create_file_from_link(image_link)\n",
    "    \n",
    "    if(file_name == -1):\n",
    "        image_metadata.append(empty_data)\n",
    "\n",
    "    else:\n",
    "        #preprocess the image\n",
    "        preprocessed_image = binarize_image(file_name)\n",
    "        a = extract_and_classify(preprocessed_image)\n",
    "        image_metadata.append(a)\n",
    "        os.remove(file_name)\n",
    "    return image_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4a5894e7-48b5-4e89-890b-f44b5aecc13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##{'weight': \n",
    "## [{'word': '02g', \n",
    "##'metadata': {'word': '02g', 'position': {'x': 723, 'y': 698, 'width': 34, 'height': 22}, 'orientation': '0 degrees', 'confidence': 69}},\n",
    "##  {'word': '0g', \n",
    "## 'metadata': {'word': '0g', 'position': {'x': 289, 'y': 328, 'width': 17, 'height': 16}, 'orientation': '+90 degrees', 'confidence': 57}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "86c17ba2-6c30-4727-9f02-bb790b49b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(columns):\n",
    "    \n",
    "    scaling_factors = {\n",
    "     '0': {'mean': np.float64(579.5818181818182), 'std': np.float64(428.7543841006432)},\n",
    "     '1': {'mean': np.float64(1007.4545454545455), 'std': np.float64(521.0780782535028)}, \n",
    "     '2': {'mean': np.float64(40.836363636363636), 'std': np.float64(35.57764780826612)},\n",
    "     '3': {'mean': np.float64(46.345454545454544), 'std': np.float64(41.67476284978546)}\n",
    "    }\n",
    "\n",
    "    new_columns = {\n",
    "        'feature_0':(columns['feature_0'] - scaling_factors['0']['mean'])/scaling_factors['0']['std'],\n",
    "        'feature_1':(columns['feature_1'] - scaling_factors['1']['mean'])/scaling_factors['1']['std'],\n",
    "        'feature_2':(columns['feature_2'] - scaling_factors['2']['mean'])/scaling_factors['2']['std'],\n",
    "        'feature_3':(columns['feature_3'] - scaling_factors['3']['mean'])/scaling_factors['3']['std'],\n",
    "        'feature_4':columns['feature_4']\n",
    "    }\n",
    "\n",
    "    return new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e0a0a973-8913-4ff7-8a39-6a1646bed789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_features(columns):\n",
    "    \n",
    "    new_data = np.array([[columns['feature_0'], \n",
    "                          columns['feature_1'], \n",
    "                          columns['feature_2'], \n",
    "                          columns['feature_3']\n",
    "                         ]])\n",
    "    zero, pos_rot, neg_rot = False, False, False\n",
    "    if(columns['feature_4'] == '0 degrees'):\n",
    "      zero = True\n",
    "    if(columns['feature_4'] == '+90 degrees'):\n",
    "      pos_rot = True\n",
    "    if(columns['feature_4'] == '-90 degrees'):\n",
    "      neg_rot = True\n",
    "\n",
    "    new_data  = np.append(new_data, [zero, pos_rot, neg_rot])\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ce1c14e-39c1-4a4d-b844-903d3a137014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "147c52fa-e9db-40b3-bb78-6f0a465ec7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_from_model(columns):\n",
    "    columns = normalize_columns(columns)\n",
    "\n",
    "    columns = format_features(columns)\n",
    "    \n",
    "    # Load the saved model\n",
    "    model = joblib.load('weight_model.pkl')\n",
    "\n",
    "    feature_names = ['feature_0', 'feature_1', 'feature_2', 'feature_3', '0 degrees', '+90 degrees', '-90 degrees']\n",
    "\n",
    "    # Convert the list to a DataFrame with correct feature names\n",
    "    features = pd.DataFrame([columns], columns=feature_names)\n",
    "\n",
    "    predicted_proba = model.predict_proba(features)\n",
    "    return predicted_proba[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "51a0649b-bb14-40f0-a93a-776c88e8eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities(image_link, category_id, entity_name):\n",
    "    data = get_data_from_image(image_link)\n",
    "    data = data[0]\n",
    "    options = []\n",
    "    required_data = data[entity_name]\n",
    "\n",
    "    for item in required_data:\n",
    "        word = item['word']\n",
    "        columns = {\n",
    "            'feature_0':item['metadata']['position']['x'],\n",
    "            'feature_1':item['metadata']['position']['y'],\n",
    "            'feature_2':item['metadata']['position']['width'],\n",
    "            'feature_3':item['metadata']['position']['height'],\n",
    "            'feature_4':item['metadata']['orientation'],\n",
    "            'feature_5':category_id\n",
    "        }\n",
    "\n",
    "        prob = get_probability_from_model(columns)\n",
    "        options.append({'word':word,'prob':prob[1]})\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6853e30f-eb3c-461a-aa5b-bc4349ee359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##testing the model\n",
    "\n",
    "def predictor(image_link, category_id, entity_name):\n",
    "    a = get_probabilities(image_link, category_id, entity_name)\n",
    "    max_prob = -1\n",
    "    best_guess = None\n",
    "    for values in a:\n",
    "        if(values['prob']>max_prob):\n",
    "            max_prob = values['prob']\n",
    "            best_guess = values['word']\n",
    "    return best_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8be0342e-6312-4c22-9112-7587f7cdd552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata [{'weight': [{'word': '30KG', 'metadata': {'word': '30KG', 'position': {'x': 1386, 'y': 43, 'width': 187, 'height': 63}, 'orientation': '0 degrees', 'confidence': 91}}, {'word': '30KG', 'metadata': {'word': '30KG,', 'position': {'x': 549, 'y': 313, 'width': 121, 'height': 42}, 'orientation': '0 degrees', 'confidence': 92}}, {'word': '30KG', 'metadata': {'word': '30KG', 'position': {'x': 1495, 'y': 1386, 'width': 63, 'height': 187}, 'orientation': '-90 degrees', 'confidence': 92}}, {'word': '30KG', 'metadata': {'word': '30KG,', 'position': {'x': 1246, 'y': 549, 'width': 42, 'height': 121}, 'orientation': '-90 degrees', 'confidence': 92}}], 'length': [{'word': '5mm', 'metadata': {'word': '5mm', 'position': {'x': 541, 'y': 181, 'width': 93, 'height': 34}, 'orientation': '0 degrees', 'confidence': 95}}, {'word': '5mm', 'metadata': {'word': '5mm', 'position': {'x': 1386, 'y': 541, 'width': 34, 'height': 93}, 'orientation': '-90 degrees', 'confidence': 95}}], 'voltage': [], 'wattage': [], 'volume': []}]\n",
      "[ 1.8808395  -1.85088298  4.1082996   0.39963144  1.          0.\n",
      "  0.        ]\n",
      "[[0.07 0.93]]\n",
      "[0.07 0.93]\n",
      "[-0.07132713 -1.33272647  2.25320226 -0.10427065  1.          0.\n",
      "  0.        ]\n",
      "[[0.19 0.81]]\n",
      "[0.19 0.81]\n",
      "[2.13506431 0.7264659  0.6229652  3.37505329 0.         0.\n",
      " 1.        ]\n",
      "[[0.1 0.9]]\n",
      "[0.1 0.9]\n",
      "[ 1.55431223 -0.87981929  0.03270695  1.79136101  0.          0.\n",
      "  1.        ]\n",
      "[[0.09 0.91]]\n",
      "[0.09 0.91]\n",
      "30KG\n"
     ]
    }
   ],
   "source": [
    "guess = predictor(\"https://m.media-amazon.com/images/I/81N73b5khVL.jpg\", 639090,\"weight\")\n",
    "# TODO: format output\n",
    "print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da7ac05-a202-4b42-9fe6-4dd085965e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
